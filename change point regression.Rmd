---
title: "change point regression"
author: "Qin Wen"
date: "1/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## DP, changepoint = 100 d0 = 15

```{r cars}
source("./function.r")
library(gglasso)
library(glmnet)

start.all = Sys.time()
print('starttime')
print(start.all)
d0 = 15# the number of nonzero elements = p-sparsity
RR = 1## replication
grid = 1##gridsize to save computational cost for DP but might increase the error, default = 1
sigma = 1## variance of data
kappa = 5## spectral norm
delta = 5 ## minimal spacing to help DP more robust
n = 200## sample size, need to be the multiple of 2*gridsize
p = 50
change.point = 100
gamma.dp.set = c(0.5,1,3,20,50,70)#c(0.001,0.005,0.01)*((ncp+1)* (sigma^2) * (d0^2))
lambda.dp.set = c(0.0001,0.001,0.01,0.1,0.3,0.8)#c(0.05,0.1,0.5)*sigma*sqrt(d0)
len.est = matrix(0,RR,1)
init.change.point = matrix(0,20,RR)
len.est = matrix(0,RR,1)
error = matrix(0,RR,1)
nrowmat = length(gamma.dp.set)
ncolmat = length(lambda.dp.set)
for (time in 1:RR){
  data = data.generate.k.fluctuate2(d0,change.point,p,n,sigma,kappa)
  X = data$X
  y = data$y
  true = data$true.change.point
  result = cv.grid.search.dp(lambda.dp.set,gamma.dp.set,X,y,grid,delta)
  ##output a table which contains estimated change points, number of estimated change points, 
  ##validation loss and training error.
  K = matrix(as.numeric(result$K),nrowmat,ncolmat)## number of estimated change points
  resmat = as.numeric(result$res)## validation loss
  cp = result$changepoint## estimated change points
  haus.index = which(matrix(resmat,nrowmat,ncolmat) == min(matrix(resmat,nrowmat,ncolmat)), arr.ind=TRUE)
  K.from.pair = c()
  for(i in 1:nrow(haus.index)){
    K.from.pair = c(K.from.pair, K[haus.index[i,1],haus.index[i,2]])
  }
  I = which.min(K.from.pair)
  haus.pair = c(gamma.dp.set[haus.index[I,1]],lambda.dp.set[haus.index[I,2]])
  # in case there are multiple min values
  selected.change.point = as.numeric(unlist(cp[haus.index[I,1],haus.index[I,2]]))
  init.change.point[1:length(selected.change.point), time] = selected.change.point
  #write.csv(init.change.point, file = "kappa_5_dp_d_0_15.csv")
  error[time,1] = Hausdorff(selected.change.point,change.point)
  #write.csv(error, file = "kappa_5_dp_error_d_0_15.csv")
  len.est[time,1] = K[haus.index[I,1],haus.index[I,2]]
  #write.csv(len.est, file = "kappa_5_dp_ncp_d_0_15.csv")
}
init.change.point ## estimated change points
error
len.est## number of estimated change points
end.all = Sys.time()
print('duration')
print(difftime(end.all, start.all, units = "secs")[[1]])

```

## DP, changepoint = 100 d0 = 50

```{r cars}
source("./function.r")
library(gglasso)
library(glmnet)

start.all = Sys.time()
print('starttime')
print(start.all)
d0 = 50# the number of nonzero elements = p-sparsity
RR = 1## replication
grid = 1##gridsize to save computational cost for DP but might increase the error, default = 1
sigma = 1## variance of data
kappa = 5## spectral norm
delta = 5 ## minimal spacing to help DP more robust
n = 200## sample size, need to be the multiple of 2*gridsize
p = 50
change.point = 100
gamma.dp.set = c(0.5,1,3,20,50,70,100)#c(0.001,0.005,0.01)*((ncp+1)* (sigma^2) * (d0^2))
lambda.dp.set = c(0.0001,0.001,0.01,0.1,0.3,0.8)#c(0.05,0.1,0.5)*sigma*sqrt(d0)
len.est = matrix(0,RR,1)
init.change.point = matrix(0,20,RR)
len.est = matrix(0,RR,1)
error = matrix(0,RR,1)
nrowmat = length(gamma.dp.set)
ncolmat = length(lambda.dp.set)
for (time in 1:RR){
  data = data.generate.k.fluctuate2(d0,change.point,p,n,sigma,kappa)
  X = data$X
  y = data$y
  true = data$true.change.point
  result = cv.grid.search.dp(lambda.dp.set,gamma.dp.set,X,y,grid,delta)
  ##output a table which contains estimated change points, number of estimated change points, 
  ##validation loss and training error.
  K = matrix(as.numeric(result$K),nrowmat,ncolmat)## number of estimated change points
  resmat = as.numeric(result$res)## validation loss
  cp = result$changepoint## estimated change points
  haus.index = which(matrix(resmat,nrowmat,ncolmat) == min(matrix(resmat,nrowmat,ncolmat)), arr.ind=TRUE)
  K.from.pair = c()
  for(i in 1:nrow(haus.index)){
    K.from.pair = c(K.from.pair, K[haus.index[i,1],haus.index[i,2]])
  }
  I = which.min(K.from.pair)
  haus.pair = c(gamma.dp.set[haus.index[I,1]],lambda.dp.set[haus.index[I,2]])
  # in case there are multiple min values
  selected.change.point = as.numeric(unlist(cp[haus.index[I,1],haus.index[I,2]]))
  init.change.point[1:length(selected.change.point), time] = selected.change.point
  #write.csv(init.change.point, file = "kappa_5_dp_d_0_15.csv")
  error[time,1] = Hausdorff(selected.change.point,change.point)
  #write.csv(error, file = "kappa_5_dp_error_d_0_15.csv")
  len.est[time,1] = K[haus.index[I,1],haus.index[I,2]]
  #write.csv(len.est, file = "kappa_5_dp_ncp_d_0_15.csv")
}
init.change.point ## estimated change points
error
len.est## number of estimated change points
end.all = Sys.time()
print('duration')
print(difftime(end.all, start.all, units = "secs")[[1]])

```

## DP, changepoint = 80

```{r}
source("./function.r")
library(gglasso)
library(glmnet)

set.seed(0)
start.all = Sys.time()
print('starttime')
print(start.all)
d0 = 5# the number of nonzero elements = p-sparsity
RR = 1## replication
grid = 1##gridsize to save computational cost for DP but might increase the error, default = 1
sigma = 1## variance of data
kappa = 5## spectral norm
delta = 5 ## minimal spacing to help DP more robust
n = 200## sample size, need to be the multiple of 2*gridsize
p = 50
change.point = c(80)
gamma.dp.set = c(0.01,0.5,1,5,10,50)#c(0.5,1,5) returns one good estimates
lambda.dp.set = c(0.01,0.1,1,1.5)#c(0.01,0.1,1)#c(0.01,0.1,1)
len.est = matrix(0,RR,1)
init.change.point = matrix(0,20,RR)
len.est = matrix(0,RR,1)
error = matrix(0,RR,1)
nrowmat = length(gamma.dp.set)
ncolmat = length(lambda.dp.set)
for (time in 1:RR){
  data = data.generate.k.fluctuate2(d0,change.point,p,n,sigma,kappa)
  X = data$X
  y = data$y
  true = data$true.change.point
  result = cv.grid.search.dp(lambda.dp.set,gamma.dp.set,X,y,grid,delta)
  ##output a table which contains estimated change points, number of estimated change points, 
  ##validation loss and training error.
  K = matrix(as.numeric(result$K),nrowmat,ncolmat)## number of estimated change points
  resmat = as.numeric(result$res)## validation loss
  cp = result$changepoint## estimated change points
  haus.index = which(matrix(resmat,nrowmat,ncolmat) == min(matrix(resmat,nrowmat,ncolmat)), arr.ind=TRUE)
  K.from.pair = c()
  for(i in 1:nrow(haus.index)){
    K.from.pair = c(K.from.pair, K[haus.index[i,1],haus.index[i,2]])
  }
  I = which.min(K.from.pair)
  haus.pair = c(gamma.dp.set[haus.index[I,1]],lambda.dp.set[haus.index[I,2]])
  # in case there are multiple min values
  selected.change.point = as.numeric(unlist(cp[haus.index[I,1],haus.index[I,2]]))
  init.change.point[1:length(selected.change.point), time] = selected.change.point
  #write.csv(init.change.point, file = "kappa_5_dp_d_0_15.csv")
  error[time,1] = Hausdorff(selected.change.point,change.point)
  #write.csv(error, file = "kappa_5_dp_error_d_0_15.csv")
  len.est[time,1] = K[haus.index[I,1],haus.index[I,2]]
  #write.csv(len.est, file = "kappa_5_dp_ncp_d_0_15.csv")
}
init.change.point ## estimated change points
error
len.est## number of estimated change points
end.all = Sys.time()
print('duration')
print(difftime(end.all, start.all, units = "secs")[[1]])

```


## DP changepoint = 80,170

```{r}
source("./function.r")
library(gglasso)
library(glmnet)

set.seed(0)
start.all = Sys.time()
print('starttime')
print(start.all)
d0 = 5# the number of nonzero elements = p-sparsity
RR = 1## replication
grid = 1##gridsize to save computational cost for DP but might increase the error, default = 1
sigma = 1## variance of data
kappa = 5## spectral norm
n = 250## sample size, need to be the multiple of 2*gridsize
p = 50
change.point = c(80,170)
gamma.dp.set = c(0.01,0.5,1,5,10,50)
lambda.dp.set = c(0.01,0.1,1,1.5)#c(0.01,0.1,1)#c(0.01,0.1,1)
delta = 5 ## minimal spacing to help DP more robust
len.est = matrix(0,RR,1)
init.change.point = matrix(0,20,RR)
len.est = matrix(0,RR,1)
error = matrix(0,RR,1)
nrowmat = length(gamma.dp.set)
ncolmat = length(lambda.dp.set)
for (time in 1:RR){
  data = data.generate.k.fluctuate2(d0,change.point,p,n,sigma,kappa)
  X = data$X
  y = data$y
  true = data$true.change.point
  result = cv.grid.search.dp(lambda.dp.set,gamma.dp.set,X,y,grid,delta)
  ##output a table which contains estimated change points, number of estimated change points, 
  ##validation loss and training error.
  K = matrix(as.numeric(result$K),nrowmat,ncolmat)## number of estimated change points
  resmat = as.numeric(result$res)## validation loss
  cp = result$changepoint## estimated change points
  haus.index = which(matrix(resmat,nrowmat,ncolmat) == min(matrix(resmat,nrowmat,ncolmat)), arr.ind=TRUE)
  K.from.pair = c()
  for(i in 1:nrow(haus.index)){
    K.from.pair = c(K.from.pair, K[haus.index[i,1],haus.index[i,2]])
  }
  I = which.min(K.from.pair)
  haus.pair = c(gamma.dp.set[haus.index[I,1]],lambda.dp.set[haus.index[I,2]])
  # in case there are multiple min values
  selected.change.point = as.numeric(unlist(cp[haus.index[I,1],haus.index[I,2]]))
  init.change.point[1:length(selected.change.point), time] = selected.change.point
  #write.csv(init.change.point, file = "kappa_5_dp_d_0_15.csv")
  error[time,1] = Hausdorff(selected.change.point,change.point)
  #write.csv(error, file = "kappa_5_dp_error_d_0_15.csv")
  len.est[time,1] = K[haus.index[I,1],haus.index[I,2]]
  #write.csv(len.est, file = "kappa_5_dp_ncp_d_0_15.csv")
}
init.change.point ## estimated change points
error
len.est## number of estimated change points
end.all = Sys.time()
print('duration')
print(difftime(end.all, start.all, units = "secs")[[1]])

```

## DPLR changepoint = 80,170
```{r}
source("./function.r")
library(gglasso)
library(glmnet)

start.all = Sys.time()
print('starttime')
print(start.all)
d0 = 15## the number of nonzero elements = p-sparsity
RR = 1##replication
grid = 1##gridsize to save computational cost for DP but might increase the error, default = 1
sigma = 1
kappa = 5
delta = 5 ## minimal spacing to help DP more robust
gamma.dp.set = c(0.01,0.5,1,5,10,50)
lambda.dp.set = c(0.01,0.1,1,1.5)
zeta.dp = c(0.01,0.1)#c(0.01,0.1,1)
len.est = matrix(0,RR,1)
lr.change.point = matrix(0,20,RR)
p = 50 
n = 250## sample size, need to be the multiple of 2*gridsize
change.point = c(80,170)
len.est = matrix(0,RR,1)
error = matrix(0,RR,1)
nrowmat = length(gamma.dp.set)*length(zeta.dp)
ncolmat = length(lambda.dp.set)
for (time in 1:RR){
  data = data.generate.k.fluctuate2(d0,change.point,p,n,sigma,kappa)
  X = data$X
  y = data$y
  true = data$true.change.point
  result = cv.grid.search.dp.lr(lambda.dp.set,gamma.dp.set,zeta.dp,X,y,grid,delta)
  ##output the table containing estimated change points, number of estimated change points, 
  ##validation loss and training error.
  resmat = c()
  cp = c()
  K = c()
  for (nzeta in 1:length(zeta.dp)){
    cp = rbind(cp,result[[(nzeta-1)*4+1]])## estimated change points
    resmat = rbind(resmat,result[[(nzeta-1)*4+3]])## validation loss
    K = rbind(K,result[[(nzeta-1)*4+2]])## number of estimated change points
  }
  haus.index = which(matrix(unlist(resmat),nrowmat,ncolmat) == min(matrix(unlist(resmat),nrowmat,ncolmat)), arr.ind=TRUE)[1,]
  # in case there are multiple min values
  selected.change.point = unlist(cp[haus.index[1],haus.index[2]])
  lr.change.point[1:length(selected.change.point), time] = selected.change.point
  #write.csv(lr.change.point, file = "1_dplr_d_0_15.csv")
  error[time,1] = Hausdorff(selected.change.point,change.point)
  #write.csv(error, file = "1_dplr_error_d_0_15.csv")
  len.est[time,1] = unlist(K[haus.index[1],haus.index[2]])
  #write.csv(len.est, file = "1_dplr_len_d_0_15.csv")
}
lr.change.point## estimated change points
error
len.est## number of estimated change points
end.all = Sys.time()
print('duration')
print(difftime(end.all, start.all, units = "secs")[[1]])

```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
